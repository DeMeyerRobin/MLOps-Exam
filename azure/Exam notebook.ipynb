{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!/anaconda/envs/azureml_py310_sdkv2/bin/python -m pip install openpyxl"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting openpyxl\n  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\nCollecting et-xmlfile (from openpyxl)\n  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\nDownloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\nDownloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\nInstalling collected packages: et-xmlfile, openpyxl\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2/2\u001b[0m [openpyxl]1/2\u001b[0m [openpyxl]\n\u001b[1A\u001b[2KSuccessfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/anaconda/envs/azureml_py310_sdkv2/bin/python -m pip install --upgrade pip\u001b[0m\n"
        }
      ],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read your Excel file\n",
        "df = pd.read_excel('got_persona_dataset_100.xlsx')\n",
        "\n",
        "# Clean data\n",
        "df = df.dropna(how='all', axis=0).dropna(how='all', axis=1)\n",
        "df.columns = df.columns.str.strip().str.replace('[^A-Za-z0-9_]', '_', regex=True)\n",
        "\n",
        "# Save as CSV\n",
        "df.to_csv('got_persona_dataset_100.csv', index=False, encoding='utf-8')\n",
        "print(f\"âœ“ Converted! Shape: {df.shape}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "âœ“ Converted! Shape: (100, 21)\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1765959964795
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Dataset\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "datastore = ws.get_default_datastore()\n",
        "\n",
        "# Upload and register\n",
        "datastore.upload_files(['got_persona_dataset_100.csv'], target_path='datasets/', overwrite=True)\n",
        "from azureml.data.datapath import DataPath\n",
        "dataset = Dataset.Tabular.from_delimited_files(DataPath(datastore, 'datasets/got_persona_dataset_100.csv'))\n",
        "dataset.register(ws, 'got-persona-dataset', create_new_version=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\"datastore.upload_files\" is deprecated after version 1.0.69. Please use \"FileDatasetFactory.upload_directory\" instead. See Dataset API change notice at https://aka.ms/dataset-deprecation.\n/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mlflow/__init__.py:41: UserWarning: Versions of mlflow (3.1.1) and mlflow-skinny (2.22.1) are different. This may lead to unexpected behavior. Please install the same version of both packages.\n  mlflow.mismatch._check_version_mismatch()\nMessage: [NOT_SUPPORTED_API_USE_ATTEMPT] The [_get_steps] API has been deprecated and is no longer supported\nPayload: {\"pid\": 5511, \"rslex_version\": \"2.22.5\", \"api_name\": \"_get_steps\", \"version\": \"5.1.6\"}\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Uploading an estimated of 1 files\nUploading got_persona_dataset_100.csv\nUploaded got_persona_dataset_100.csv, 1 files out of an estimated total of 1\nUploaded 1 files\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "{\n  \"definition\": \"EnginelessDataflow:\\n---\\ntype: mltable\\npaths:\\n  - pattern: \\\"azureml://subscriptions/ebc57341-e881-4473-9659-d8076026bd45/resourcegroups/azure-ai/workspaces/demeyer-robin-ml/datastores/workspaceblobstore/paths/datasets/got_persona_dataset_100.csv\\\"\\ntransformations:\\n  - read_delimited:\\n      path_column: Path\\n      include_path_column: false\\n      encoding: utf8\\n      support_multi_line: false\\n      delimiter: \\\",\\\"\\n      empty_as_string: false\\n      partition_size: 20971520\\n      header: all_files_same_headers\\n      infer_column_types: false\\n  - convert_column_types:\\n      - columns: house_affiliation\\n        column_type: string\\n      - columns: ruthlessness_1to5\\n        column_type: int\\n      - columns: trait_impulsive\\n        column_type: boolean\\n      - columns: trait_vengeful\\n        column_type: boolean\\n      - columns: trait_loyal\\n        column_type: boolean\\n      - columns: combat_skill_1to5\\n        column_type: int\\n      - columns: species\\n        column_type: string\\n      - columns: primary_role\\n        column_type: string\\n      - columns: leadership_1to5\\n        column_type: int\\n      - columns: intelligence_1to5\\n        column_type: int\\n      - columns: trait_strategic\\n        column_type: boolean\\n      - columns: region\\n        column_type: string\\n      - columns: status\\n        column_type: string\\n      - columns: diplomacy_1to5\\n        column_type: int\\n      - columns: honour_1to5\\n        column_type: int\\n      - columns: character_name\\n        column_type: string\\n      - columns: trait_charismatic\\n        column_type: boolean\\n      - columns: alignment\\n        column_type: string\\n      - columns: character_id\\n        column_type: string\\n      - columns: trait_scheming\\n        column_type: boolean\\n      - columns: feature_set_version\\n        column_type: float\\nmetadata:\\n  infer_column_types: \\\"False\\\"\\n\",\n  \"registration\": {\n    \"id\": \"b615ec19-d621-407b-902c-2a9d90fa9023\",\n    \"name\": \"got-persona-dataset\",\n    \"version\": 1,\n    \"workspace\": \"Workspace.create(name='demeyer-robin-ml', subscription_id='ebc57341-e881-4473-9659-d8076026bd45', resource_group='azure-ai')\"\n  }\n}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1765960000943
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import MLClient, Input, Output, command\n",
        "from azure.ai.ml.entities import Environment\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.ml.dsl import pipeline\n",
        "from azureml.core import Workspace, Dataset\n",
        "\n",
        "credential = DefaultAzureCredential()\n",
        "ml_client = MLClient.from_config(credential=credential)\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "print(f\"âœ“ Connected to: {ml_client.workspace_name}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: /config.json\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "âœ“ Connected to: demeyer-robin-ml\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1765960956280
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your existing tabular dataset\n",
        "dataset = Dataset.get_by_name(ws, name='got-persona-dataset', version='1')\n",
        "df = dataset.to_pandas_dataframe()\n",
        "\n",
        "# Save as data.csv (required by your prepare_component.py)\n",
        "df.to_csv('data.csv', index=False)\n",
        "print(f\"âœ“ Dataset shape: {df.shape}\")\n",
        "\n",
        "# Upload to datastore\n",
        "datastore = ws.get_default_datastore()\n",
        "datastore.upload_files(\n",
        "    files=['data.csv'],\n",
        "    target_path='got_input/',\n",
        "    overwrite=True\n",
        ")\n",
        "print(\"âœ“ Uploaded to: got_input/data.csv\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'infer_column_types': 'False', 'activity': 'to_pandas_dataframe'}\n{'infer_column_types': 'False', 'activity': 'to_pandas_dataframe', 'activityApp': 'TabularDataset'}\nâœ“ Dataset shape: (100, 21)\nUploading an estimated of 1 files\nUploading data.csv\nUploaded data.csv, 1 files out of an estimated total of 1\nUploaded 1 files\nâœ“ Uploaded to: got_input/data.csv\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1765960982700
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = Environment(\n",
        "    name=\"got-prepare-env\",\n",
        "    conda_file=\"conda.yaml\",  # Uses your existing file\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
        ")\n",
        "env = ml_client.environments.create_or_update(env)\n",
        "print(f\"âœ“ Environment: {env.name}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "âœ“ Environment: got-prepare-env\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1765960995675
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import load_component\n",
        "\n",
        "# First, create a component YAML file\n",
        "component_yaml = \"\"\"\n",
        "$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n",
        "name: prepare_got_data\n",
        "display_name: Prepare GOT Data\n",
        "version: 1\n",
        "type: command\n",
        "\n",
        "inputs:\n",
        "  input_folder:\n",
        "    type: uri_folder\n",
        "  target_col:\n",
        "    type: string\n",
        "    default: house_affiliation\n",
        "  test_size:\n",
        "    type: number\n",
        "    default: 0.2\n",
        "  seed:\n",
        "    type: integer\n",
        "    default: 42\n",
        "  stratify:\n",
        "    type: integer\n",
        "    default: 1\n",
        "\n",
        "outputs:\n",
        "  out_train:\n",
        "    type: uri_folder\n",
        "  out_test:\n",
        "    type: uri_folder\n",
        "\n",
        "code: .\n",
        "\n",
        "environment: azureml:got-prepare-env@latest\n",
        "\n",
        "command: >\n",
        "  python prepare_component.py\n",
        "  --input_folder ${{inputs.input_folder}}\n",
        "  --target_col ${{inputs.target_col}}\n",
        "  --test_size ${{inputs.test_size}}\n",
        "  --seed ${{inputs.seed}}\n",
        "  --stratify ${{inputs.stratify}}\n",
        "  --out_train ${{outputs.out_train}}\n",
        "  --out_test ${{outputs.out_test}}\n",
        "\"\"\"\n",
        "\n",
        "# Save YAML\n",
        "with open('prepare_component.yaml', 'w') as f:\n",
        "    f.write(component_yaml)\n",
        "\n",
        "# Load and register the component\n",
        "prepare_component = load_component(source='prepare_component.yaml')\n",
        "prepare_component = ml_client.components.create_or_update(prepare_component)\n",
        "\n",
        "print(f\"âœ“ Component registered!\")\n",
        "print(f\"  Name: {prepare_component.name}\")\n",
        "print(f\"  Version: {prepare_component.version}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\rUploading Exam (0.07 MBs):   0%|          | 0/73460 [00:00<?, ?it/s]\rUploading Exam (0.07 MBs):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 73015/73460 [00:00<00:00, 582384.91it/s]\rUploading Exam (0.07 MBs): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73460/73460 [00:00<00:00, 573894.40it/s]\n\n\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "âœ“ Component registered!\n  Name: prepare_got_data\n  Version: 1\n"
        }
      ],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1765961868459
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@pipeline(name=\"got_data_preparation\")\n",
        "def data_prep_pipeline(input_data, target_col=\"house_affiliation\"):\n",
        "    step = prepare_component(\n",
        "        input_folder=input_data,\n",
        "        target_col=target_col,\n",
        "        test_size=0.2,\n",
        "        seed=42,\n",
        "        stratify=1\n",
        "    )\n",
        "    return {\n",
        "        \"train_data\": step.outputs.out_train,\n",
        "        \"test_data\": step.outputs.out_test,\n",
        "    }\n",
        "\n",
        "print(\"âœ“ Pipeline defined\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "âœ“ Pipeline defined\n"
        }
      ],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1765961943034
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_job = data_prep_pipeline(\n",
        "    input_data=Input(\n",
        "        type=\"uri_folder\",\n",
        "        path=\"azureml://datastores/workspaceblobstore/paths/got_input/\"\n",
        "    ),\n",
        "    target_col=\"house_affiliation\"\n",
        ")\n",
        "\n",
        "# Set default compute for the pipeline\n",
        "pipeline_job.settings.default_compute = \"RDM-compute\"\n",
        "\n",
        "pipeline_job = ml_client.jobs.create_or_update(\n",
        "    pipeline_job,\n",
        "    experiment_name=\"got_data_preparation\"\n",
        ")\n",
        "\n",
        "print(f\"\\nâœ“ Pipeline submitted!\")\n",
        "print(f\"View at: {pipeline_job.studio_url}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\npathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nâœ“ Pipeline submitted!\nView at: https://ml.azure.com/runs/stoic_candle_tyc55kplsm?wsid=/subscriptions/ebc57341-e881-4473-9659-d8076026bd45/resourcegroups/azure-ai/workspaces/demeyer-robin-ml&tid=4ded4bb1-6bff-42b3-aed7-6a36a503bf7a\n"
        }
      ],
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1765961956031
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_env = Environment(\n",
        "    name=\"got-train-dt-env\",\n",
        "    conda_file=\"conda_train.yaml\",  # Uses your existing file\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
        ")\n",
        "training_env = ml_client.environments.create_or_update(training_env)\n",
        "print(f\"âœ“ Training environment registered: {training_env.name}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "ActivityCompleted: Activity=Environment.CreateOrUpdate, HowEnded=Failure, Duration=289.13 [ms], Exception=ResourceExistsError, ErrorCategory=UserError, ErrorMessage=(UserError) Environment got-train-dt-env with version 1 is already registered and cannot be changed.\nCode: UserError\nMessage: Environment got-train-dt-env with version 1 is already registered and cannot be changed.\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "âœ“ Training environment registered: got-train-dt-env\n"
        }
      ],
      "execution_count": 38,
      "metadata": {
        "gather": {
          "logged": 1765964305243
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "# Create a registry client to access azureml registry components\n",
        "registry_client = MLClient(\n",
        "    credential=DefaultAzureCredential(),\n",
        "    subscription_id=ml_client.subscription_id,\n",
        "    resource_group_name=ml_client.resource_group_name,\n",
        "    registry_name=\"azureml\"\n",
        ")\n",
        "\n",
        "# Get the register_model component from the registry\n",
        "register_model_component = registry_client.components.get(\n",
        "    name=\"register_model\",\n",
        "    version=\"0.0.21\"\n",
        ")\n",
        "\n",
        "print(\"âœ“ Loaded register_model component from azureml registry\")\n",
        "print(f\"  Component: {register_model_component.name}\")\n",
        "print(f\"  Version: {register_model_component.version}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "âœ“ Loaded register_model component from azureml registry\n  Component: register_model\n  Version: 0.0.21\n"
        }
      ],
      "execution_count": 46,
      "metadata": {
        "gather": {
          "logged": 1765964902057
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_component_code_no_registration = \"\"\"import argparse\n",
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import joblib\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--train_ready\", type=str, required=True)\n",
        "    parser.add_argument(\"--test_ready\", type=str, required=True)\n",
        "    parser.add_argument(\"--target_col\", type=str, default=\"house_affiliation\")\n",
        "    parser.add_argument(\"--max_depth\", type=int, default=10)\n",
        "    parser.add_argument(\"--min_samples_split\", type=int, default=2)\n",
        "    parser.add_argument(\"--min_samples_leaf\", type=int, default=1)\n",
        "    parser.add_argument(\"--random_state\", type=int, default=42)\n",
        "    parser.add_argument(\"--model_output\", type=str, required=True)\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    print(\"=\"*60)\n",
        "    print(\"Decision Tree Training Component\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    print(\"\\\\n1. Loading data...\")\n",
        "    X_train_path = os.path.join(args.train_ready, \"X_train.csv\")\n",
        "    y_train_path = os.path.join(args.train_ready, \"y_train.csv\")\n",
        "    X_test_path = os.path.join(args.test_ready, \"X_test.csv\")\n",
        "    y_test_path = os.path.join(args.test_ready, \"y_test.csv\")\n",
        "\n",
        "    for p in [X_train_path, y_train_path, X_test_path, y_test_path]:\n",
        "        if not os.path.exists(p):\n",
        "            raise FileNotFoundError(f\"Missing required file: {p}\")\n",
        "\n",
        "    X_train = pd.read_csv(X_train_path)\n",
        "    y_train = pd.read_csv(y_train_path)[args.target_col].astype(str)\n",
        "    X_test = pd.read_csv(X_test_path)\n",
        "    y_test = pd.read_csv(y_test_path)[args.target_col].astype(str)\n",
        "\n",
        "    print(f\"   Train: {X_train.shape[0]} samples, {X_train.shape[1]} features\")\n",
        "    print(f\"   Test: {X_test.shape[0]} samples\")\n",
        "\n",
        "    mlflow.start_run()\n",
        "\n",
        "    print(\"\\\\n2. Training Decision Tree Classifier...\")\n",
        "    mlflow.log_param(\"max_depth\", args.max_depth)\n",
        "    mlflow.log_param(\"min_samples_split\", args.min_samples_split)\n",
        "    mlflow.log_param(\"min_samples_leaf\", args.min_samples_leaf)\n",
        "    mlflow.log_param(\"random_state\", args.random_state)\n",
        "    mlflow.log_param(\"target_col\", args.target_col)\n",
        "\n",
        "    clf = DecisionTreeClassifier(\n",
        "        max_depth=args.max_depth,\n",
        "        min_samples_split=args.min_samples_split,\n",
        "        min_samples_leaf=args.min_samples_leaf,\n",
        "        random_state=args.random_state,\n",
        "    )\n",
        "    clf.fit(X_train, y_train)\n",
        "    print(\"   âœ“ Model trained\")\n",
        "\n",
        "    print(\"\\\\n3. Evaluating model...\")\n",
        "    y_pred_train = clf.predict(X_train)\n",
        "    y_pred_test = clf.predict(X_test)\n",
        "    \n",
        "    train_acc = float(accuracy_score(y_train, y_pred_train))\n",
        "    test_acc = float(accuracy_score(y_test, y_pred_test))\n",
        "    \n",
        "    print(f\"   Training accuracy: {train_acc:.4f}\")\n",
        "    print(f\"   Test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "    mlflow.log_metric(\"train_accuracy\", train_acc)\n",
        "    mlflow.log_metric(\"test_accuracy\", test_acc)\n",
        "\n",
        "    report = classification_report(y_test, y_pred_test, output_dict=True, zero_division=0)\n",
        "    \n",
        "    for label, metrics in report.items():\n",
        "        if isinstance(metrics, dict):\n",
        "            mlflow.log_metric(f\"{label}_precision\", metrics['precision'])\n",
        "            mlflow.log_metric(f\"{label}_recall\", metrics['recall'])\n",
        "            mlflow.log_metric(f\"{label}_f1\", metrics['f1-score'])\n",
        "\n",
        "    print(\"\\\\n4. Saving model...\")\n",
        "    os.makedirs(args.model_output, exist_ok=True)\n",
        "    model_path = os.path.join(args.model_output, \"model.pkl\")\n",
        "    joblib.dump(clf, model_path)\n",
        "    print(f\"   Model saved: {model_path}\")\n",
        "\n",
        "    # Log model to MLflow (but don't register yet - that's done in separate step)\n",
        "    mlflow.sklearn.log_model(clf, \"decision_tree_model\")\n",
        "\n",
        "    report_path = os.path.join(args.model_output, \"metrics.json\")\n",
        "    with open(report_path, 'w') as f:\n",
        "        json.dump({\n",
        "            \"train_accuracy\": train_acc,\n",
        "            \"test_accuracy\": test_acc,\n",
        "            \"classification_report\": report\n",
        "        }, f, indent=2)\n",
        "\n",
        "    mlflow.end_run()\n",
        "\n",
        "    print(\"\\\\n\" + \"=\"*60)\n",
        "    print(\"âœ“ Training completed successfully!\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\"\"\"\n",
        "\n",
        "with open('train_component.py', 'w') as f:\n",
        "    f.write(train_component_code_no_registration)\n",
        "\n",
        "print(\"âœ“ train_component.py updated (without registration)\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "âœ“ train_component.py updated (without registration)\n"
        }
      ],
      "execution_count": 47,
      "metadata": {
        "gather": {
          "logged": 1765964927351
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_component_yaml = \"\"\"\n",
        "$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n",
        "name: train_decision_tree\n",
        "display_name: Train Decision Tree Classifier\n",
        "version: 3\n",
        "type: command\n",
        "\n",
        "inputs:\n",
        "  train_ready:\n",
        "    type: uri_folder\n",
        "  test_ready:\n",
        "    type: uri_folder\n",
        "  target_col:\n",
        "    type: string\n",
        "    default: house_affiliation\n",
        "  max_depth:\n",
        "    type: integer\n",
        "    default: 10\n",
        "  min_samples_split:\n",
        "    type: integer\n",
        "    default: 2\n",
        "  min_samples_leaf:\n",
        "    type: integer\n",
        "    default: 1\n",
        "  random_state:\n",
        "    type: integer\n",
        "    default: 42\n",
        "\n",
        "outputs:\n",
        "  model_output:\n",
        "    type: uri_folder\n",
        "\n",
        "code: .\n",
        "environment: azureml:got-train-dt-env@latest\n",
        "\n",
        "command: >\n",
        "  python train_component.py\n",
        "  --train_ready ${{inputs.train_ready}}\n",
        "  --test_ready ${{inputs.test_ready}}\n",
        "  --target_col ${{inputs.target_col}}\n",
        "  --max_depth ${{inputs.max_depth}}\n",
        "  --min_samples_split ${{inputs.min_samples_split}}\n",
        "  --min_samples_leaf ${{inputs.min_samples_leaf}}\n",
        "  --random_state ${{inputs.random_state}}\n",
        "  --model_output ${{outputs.model_output}}\n",
        "\"\"\"\n",
        "\n",
        "with open('train_component.yaml', 'w') as f:\n",
        "    f.write(train_component_yaml)\n",
        "\n",
        "from azure.ai.ml import load_component\n",
        "train_component = load_component(source='train_component.yaml')\n",
        "train_component = ml_client.components.create_or_update(train_component)\n",
        "\n",
        "print(f\"âœ“ Training component v3 registered\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\rUploading Exam (0.12 MBs):   0%|          | 0/115476 [00:00<?, ?it/s]\rUploading Exam (0.12 MBs): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115476/115476 [00:00<00:00, 1533818.22it/s]\n\n\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "âœ“ Training component v3 registered\n"
        }
      ],
      "execution_count": 48,
      "metadata": {
        "gather": {
          "logged": 1765964957277
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@pipeline(\n",
        "    name=\"got_complete_pipeline_with_registration\",\n",
        "    description=\"Complete pipeline: Data prep + Training + Model registration\"\n",
        ")\n",
        "def complete_got_pipeline_3steps(input_data, target_col=\"house_affiliation\", model_name=\"got_decision_tree_model\"):\n",
        "    # Step 1: Data preparation\n",
        "    prep_step = prepare_component(\n",
        "        input_folder=input_data,\n",
        "        target_col=target_col,\n",
        "        test_size=0.2,\n",
        "        seed=42,\n",
        "        stratify=1\n",
        "    )\n",
        "    \n",
        "    # Step 2: Training\n",
        "    train_step = train_component(\n",
        "        train_ready=prep_step.outputs.out_train,\n",
        "        test_ready=prep_step.outputs.out_test,\n",
        "        target_col=target_col,\n",
        "        max_depth=10,\n",
        "        min_samples_split=2,\n",
        "        min_samples_leaf=1,\n",
        "        random_state=42\n",
        "    )\n",
        "    \n",
        "    # Step 3: Register model using Azure's component\n",
        "    register_step = register_model_component(\n",
        "        model_path=train_step.outputs.model_output,\n",
        "        model_name=model_name,\n",
        "        model_type=\"custom_model\"\n",
        "    )\n",
        "    \n",
        "    return {\n",
        "        \"train_data\": prep_step.outputs.out_train,\n",
        "        \"test_data\": prep_step.outputs.out_test,\n",
        "        \"trained_model\": train_step.outputs.model_output,\n",
        "        \"registered_model\": register_step.outputs.registration_details_folder  # â† Fixed!\n",
        "    }\n",
        "\n",
        "print(\"âœ“ Complete 3-step pipeline defined\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "âœ“ Complete 3-step pipeline defined\n"
        }
      ],
      "execution_count": 51,
      "metadata": {
        "gather": {
          "logged": 1765965027207
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Azure's pre-built curated environment (no build needed!)\n",
        "from azure.ai.ml.entities import Environment\n",
        "\n",
        "curated_env_name = \"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu:1\"\n",
        "\n",
        "# Update training component to use curated environment\n",
        "train_component_yaml_curated = \"\"\"\n",
        "$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n",
        "name: train_decision_tree\n",
        "display_name: Train Decision Tree Classifier\n",
        "version: 4\n",
        "type: command\n",
        "\n",
        "inputs:\n",
        "  train_ready:\n",
        "    type: uri_folder\n",
        "  test_ready:\n",
        "    type: uri_folder\n",
        "  target_col:\n",
        "    type: string\n",
        "    default: house_affiliation\n",
        "  max_depth:\n",
        "    type: integer\n",
        "    default: 10\n",
        "  min_samples_split:\n",
        "    type: integer\n",
        "    default: 2\n",
        "  min_samples_leaf:\n",
        "    type: integer\n",
        "    default: 1\n",
        "  random_state:\n",
        "    type: integer\n",
        "    default: 42\n",
        "\n",
        "outputs:\n",
        "  model_output:\n",
        "    type: uri_folder\n",
        "\n",
        "code: .\n",
        "environment: azureml:AzureML-sklearn-1.0-ubuntu20.04-py38-cpu:1\n",
        "\n",
        "command: >\n",
        "  python train_component.py\n",
        "  --train_ready ${{inputs.train_ready}}\n",
        "  --test_ready ${{inputs.test_ready}}\n",
        "  --target_col ${{inputs.target_col}}\n",
        "  --max_depth ${{inputs.max_depth}}\n",
        "  --min_samples_split ${{inputs.min_samples_split}}\n",
        "  --min_samples_leaf ${{inputs.min_samples_leaf}}\n",
        "  --random_state ${{inputs.random_state}}\n",
        "  --model_output ${{outputs.model_output}}\n",
        "\"\"\"\n",
        "\n",
        "with open('train_component.yaml', 'w') as f:\n",
        "    f.write(train_component_yaml_curated)\n",
        "\n",
        "from azure.ai.ml import load_component\n",
        "train_component = load_component(source='train_component.yaml')\n",
        "train_component = ml_client.components.create_or_update(train_component)\n",
        "\n",
        "print(f\"âœ“ Training component v4 registered with curated environment\")\n",
        "print(\"  This environment is pre-built and won't need to build!\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\rUploading Exam (0.13 MBs):   0%|          | 0/134605 [00:00<?, ?it/s]\rUploading Exam (0.13 MBs): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 134605/134605 [00:00<00:00, 1735704.35it/s]\n\n\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "âœ“ Training component v4 registered with curated environment\n  This environment is pre-built and won't need to build!\n"
        }
      ],
      "execution_count": 53,
      "metadata": {
        "gather": {
          "logged": 1765965260294
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "complete_job = complete_got_pipeline_3steps(\n",
        "    input_data=Input(\n",
        "        type=\"uri_folder\",\n",
        "        path=\"azureml://datastores/workspaceblobstore/paths/got_input/\"\n",
        "    ),\n",
        "    target_col=\"house_affiliation\",\n",
        "    model_name=\"got_decision_tree_model\"\n",
        ")\n",
        "\n",
        "complete_job.settings.default_compute = \"serverless\"\n",
        "\n",
        "complete_job = ml_client.jobs.create_or_update(\n",
        "    complete_job,\n",
        "    experiment_name=\"got_complete_pipeline\"\n",
        ")\n",
        "\n",
        "print(f\"\\nâœ“ Complete 3-step pipeline submitted!\")\n",
        "print(f\"View at: {complete_job.studio_url}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\npathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\npathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\npathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nâœ“ Complete 3-step pipeline submitted!\nView at: https://ml.azure.com/runs/maroon_cup_7fxbbtyhyb?wsid=/subscriptions/ebc57341-e881-4473-9659-d8076026bd45/resourcegroups/azure-ai/workspaces/demeyer-robin-ml&tid=4ded4bb1-6bff-42b3-aed7-6a36a503bf7a\n"
        }
      ],
      "execution_count": 54,
      "metadata": {
        "gather": {
          "logged": 1765965281084
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, get the latest training component\n",
        "train_component_latest = ml_client.components.get(\n",
        "    name=\"train_decision_tree\",\n",
        "    label=\"latest\"  # This gets the absolute latest version\n",
        ")\n",
        "\n",
        "print(f\"Latest component version: {train_component_latest.version}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Latest component version: 4\n"
        }
      ],
      "execution_count": 55,
      "metadata": {
        "gather": {
          "logged": 1765966006195
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_component_yaml_v5 = \"\"\"\n",
        "$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n",
        "name: train_decision_tree\n",
        "display_name: Train Decision Tree Classifier\n",
        "version: 5\n",
        "type: command\n",
        "\n",
        "inputs:\n",
        "  train_ready:\n",
        "    type: uri_folder\n",
        "  test_ready:\n",
        "    type: uri_folder\n",
        "  target_col:\n",
        "    type: string\n",
        "    default: house_affiliation\n",
        "  max_depth:\n",
        "    type: integer\n",
        "    default: 10\n",
        "  min_samples_split:\n",
        "    type: integer\n",
        "    default: 2\n",
        "  min_samples_leaf:\n",
        "    type: integer\n",
        "    default: 1\n",
        "  random_state:\n",
        "    type: integer\n",
        "    default: 42\n",
        "\n",
        "outputs:\n",
        "  model_output:\n",
        "    type: uri_folder\n",
        "\n",
        "code: .\n",
        "environment: azureml:AzureML-sklearn-1.0-ubuntu20.04-py38-cpu:1\n",
        "\n",
        "command: >\n",
        "  python train_component.py\n",
        "  --train_ready ${{inputs.train_ready}}\n",
        "  --test_ready ${{inputs.test_ready}}\n",
        "  --target_col ${{inputs.target_col}}\n",
        "  --max_depth ${{inputs.max_depth}}\n",
        "  --min_samples_split ${{inputs.min_samples_split}}\n",
        "  --min_samples_leaf ${{inputs.min_samples_leaf}}\n",
        "  --random_state ${{inputs.random_state}}\n",
        "  --model_output ${{outputs.model_output}}\n",
        "\"\"\"\n",
        "\n",
        "with open('train_component.yaml', 'w') as f:\n",
        "    f.write(train_component_yaml_v5)\n",
        "\n",
        "print(\"âœ“ train_component.yaml v5 created with curated environment\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "âœ“ train_component.yaml v5 created with curated environment\n"
        }
      ],
      "execution_count": 56,
      "metadata": {
        "gather": {
          "logged": 1765966069766
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import load_component\n",
        "\n",
        "train_component_v5 = load_component(source='train_component.yaml')\n",
        "train_component_v5 = ml_client.components.create_or_update(train_component_v5)\n",
        "\n",
        "print(f\"âœ“ Component v5 registered!\")\n",
        "print(f\"  Name: {train_component_v5.name}\")\n",
        "print(f\"  Version: {train_component_v5.version}\")\n",
        "print(f\"  Environment: AzureML-sklearn-1.0-ubuntu20.04-py38-cpu:1 (CURATED)\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\rUploading Exam (0.13 MBs):   0%|          | 0/128462 [00:00<?, ?it/s]\rUploading Exam (0.13 MBs): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128462/128462 [00:00<00:00, 1440977.00it/s]\n\n\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "âœ“ Component v5 registered!\n  Name: train_decision_tree\n  Version: 5\n  Environment: AzureML-sklearn-1.0-ubuntu20.04-py38-cpu:1 (CURATED)\n"
        }
      ],
      "execution_count": 57,
      "metadata": {
        "gather": {
          "logged": 1765966086898
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@pipeline(\n",
        "    name=\"got_complete_pipeline_with_registration\",\n",
        "    description=\"Complete pipeline: Data prep + Training + Model registration\"\n",
        ")\n",
        "def complete_got_pipeline_v5(input_data, target_col=\"house_affiliation\", model_name=\"got_decision_tree_model\"):\n",
        "    # Step 1: Data preparation\n",
        "    prep_step = prepare_component(\n",
        "        input_folder=input_data,\n",
        "        target_col=target_col,\n",
        "        test_size=0.2,\n",
        "        seed=42,\n",
        "        stratify=1\n",
        "    )\n",
        "    \n",
        "    # Step 2: Training with V5 (curated environment)\n",
        "    train_step = train_component_v5(\n",
        "        train_ready=prep_step.outputs.out_train,\n",
        "        test_ready=prep_step.outputs.out_test,\n",
        "        target_col=target_col,\n",
        "        max_depth=10,\n",
        "        min_samples_split=2,\n",
        "        min_samples_leaf=1,\n",
        "        random_state=42\n",
        "    )\n",
        "    \n",
        "    # Step 3: Register model\n",
        "    register_step = register_model_component(\n",
        "        model_path=train_step.outputs.model_output,\n",
        "        model_name=model_name,\n",
        "        model_type=\"custom_model\"\n",
        "    )\n",
        "    \n",
        "    return {\n",
        "        \"train_data\": prep_step.outputs.out_train,\n",
        "        \"test_data\": prep_step.outputs.out_test,\n",
        "        \"trained_model\": train_step.outputs.model_output,\n",
        "        \"registered_model\": register_step.outputs.registration_details_folder\n",
        "    }\n",
        "\n",
        "print(\"âœ“ Pipeline defined with component v5\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "âœ“ Pipeline defined with component v5\n"
        }
      ],
      "execution_count": 58,
      "metadata": {
        "gather": {
          "logged": 1765966110682
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "complete_job_v5 = complete_got_pipeline_v5(\n",
        "    input_data=Input(\n",
        "        type=\"uri_folder\",\n",
        "        path=\"azureml://datastores/workspaceblobstore/paths/got_input/\"\n",
        "    ),\n",
        "    target_col=\"house_affiliation\",\n",
        "    model_name=\"got_decision_tree_model\"\n",
        ")\n",
        "\n",
        "complete_job_v5.settings.default_compute = \"serverless\"\n",
        "\n",
        "complete_job_v5 = ml_client.jobs.create_or_update(\n",
        "    complete_job_v5,\n",
        "    experiment_name=\"got_complete_pipeline\"\n",
        ")\n",
        "\n",
        "print(f\"\\nâœ“ Pipeline submitted with V5 (CURATED ENVIRONMENT)!\")\n",
        "print(f\"View at: {complete_job_v5.studio_url}\")\n",
        "print(\"\\nThis should start immediately - no building needed! ðŸš€\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\npathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\npathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\npathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nâœ“ Pipeline submitted with V5 (CURATED ENVIRONMENT)!\nView at: https://ml.azure.com/runs/orange_quince_8bwp8spt2w?wsid=/subscriptions/ebc57341-e881-4473-9659-d8076026bd45/resourcegroups/azure-ai/workspaces/demeyer-robin-ml&tid=4ded4bb1-6bff-42b3-aed7-6a36a503bf7a\n\nThis should start immediately - no building needed! ðŸš€\n"
        }
      ],
      "execution_count": 59,
      "metadata": {
        "gather": {
          "logged": 1765966121665
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Available compute targets:\")\n",
        "compute_list = []\n",
        "for compute in ml_client.compute.list():\n",
        "    print(f\"  {compute.name} - {compute.type}\")\n",
        "    compute_list.append(compute.name)\n",
        "\n",
        "if compute_list:\n",
        "    print(f\"\\nYou can use: {compute_list[0]}\")\n",
        "else:\n",
        "    print(\"\\nOnly serverless available\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Available compute targets:\n  RDM-compute - computeinstance\n\nYou can use: RDM-compute\n"
        }
      ],
      "execution_count": 62,
      "metadata": {
        "gather": {
          "logged": 1765966749663
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cancel the stuck job\n",
        "try:\n",
        "    ml_client.jobs.cancel(complete_job_v5.name)\n",
        "    print(\"âœ“ Cancelled stuck job\")\n",
        "except:\n",
        "    print(\"Job already finished or cancelled\")\n",
        "\n",
        "# Re-run with explicit compute\n",
        "complete_job_v5_retry = complete_got_pipeline_v5(\n",
        "    input_data=Input(\n",
        "        type=\"uri_folder\",\n",
        "        path=\"azureml://datastores/workspaceblobstore/paths/got_input/\"\n",
        "    ),\n",
        "    target_col=\"house_affiliation\",\n",
        "    model_name=\"got_decision_tree_model\"\n",
        ")\n",
        "\n",
        "# Use first available compute or serverless\n",
        "if compute_list:\n",
        "    complete_job_v5_retry.settings.default_compute = compute_list[0]\n",
        "    print(f\"Using compute: {compute_list[0]}\")\n",
        "else:\n",
        "    complete_job_v5_retry.settings.default_compute = \"serverless\"\n",
        "    print(\"Using serverless compute\")\n",
        "\n",
        "complete_job_v5_retry = ml_client.jobs.create_or_update(\n",
        "    complete_job_v5_retry,\n",
        "    experiment_name=\"got_complete_pipeline\"\n",
        ")\n",
        "\n",
        "print(f\"\\nâœ“ Pipeline re-submitted!\")\n",
        "print(f\"View at: {complete_job_v5_retry.studio_url}\")\n",
        "print(\"\\nWatch it closely - training should start within 2-3 minutes with curated env\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\npathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\npathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\npathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nâœ“ Pipeline re-submitted!\nView at: https://ml.azure.com/runs/zen_planet_clwdz5zp5g?wsid=/subscriptions/ebc57341-e881-4473-9659-d8076026bd45/resourcegroups/azure-ai/workspaces/demeyer-robin-ml&tid=4ded4bb1-6bff-42b3-aed7-6a36a503bf7a\n\nWatch it closely - training should start within 2-3 minutes with curated env\n"
        }
      ],
      "execution_count": 63,
      "metadata": {
        "gather": {
          "logged": 1765966773544
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.18",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "nl"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}